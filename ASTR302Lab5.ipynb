{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ASTR302 Lab 5: Removing Instrumental Signatures and Making a Final CCD Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab you will how to remove the basic instrumental signatures in a CCD image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing the Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nature of counting statistics and many other sources of noise, namely that they are symmetric and Gaussian distributed, hits a wall when confronted with the positive definite quality of signal detection. To maintain the statistically nice properties of Gaussian noise, we (more accurately whomever constructed the CCD camera you are using) typically move the average value of a pixel away from 0, even when the camera shutter is left closed and the exposure time is equal to 0 seconds. The numerical fact then that a signal of 0 is equal to some positive non-zero value is referred to as a bias or sometimes as a 'fat zero'.\n",
    "\n",
    "This is a purely fictional added value devised by the read out electronics. There are less standard ways of actually generating charge in the pixels by briefly flashing them with light. This is typically called a pre-flash and is generally done for other reasons that we will discuss elsewhere. \n",
    "\n",
    "Because the bias is added in the read-out electronics, we can also just have the CCD do additional reads even once all of the pixels in the register are read out. This will add apparent extra pixels to the final image that you have, although these extra pixels do not correspond to real pixels on the detector. These will have only the bias in them, independent of whether the exposure time was not zero and the shutter was open or closed. When we do this for each row, we create a vertical band of bias columns (could also be a set of rows) that is called the overscan region. We will use this region to measure the bias level that we will then subtract from the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, lets import the packages you will be needing for this Lab and take a look at an image. We use the fits image format. You can learn about the fits utilities in astropy at https://docs.astropy.org/en/stable/io/fits/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "# define the image, open, and read the header information\n",
    "filename = 'imacs_image.fits'\n",
    "hdu = fits.open(filename)[0]\n",
    "image = hdu.data\n",
    "hdr = hdu.header\n",
    "\n",
    "# plot the image, with minimum and maximum levels set by hand\n",
    "ax = plt.subplot()\n",
    "ax.imshow(image,cmap='gray',vmin=1100,vmax=1480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an image of the sky. You can see point sources, which are most likely stars, and resolved objects, which are most likely galaxies. You can also see the dark band on the right hand side - this is the overscan region. The bias is added throughout the image, and yet the overscan region is darker than the rest of the image. <div class=\"alert alert-info\">Why is this so? Answer below.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always good practice to take a close look at your data to find flaws and limitations. Lets take a look at the same image above, but this time scale the image so that we only display pixel values between 1150 and 1210. <div class=\"alert alert-info\">Describe what you see now? Answer below.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets work on subtracting the bias level. We will determine the bias level using the overscan region and then trim the image so that it no longer has the overscan region (we don't need it anymore once we've measured and subtracted off the bias level). \n",
    "\n",
    "First, we need to determine the region of the image that the overscan region occupies. Lets do that by taking cuts across and image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot a cut at row 820 (row was arbitrarily chosen)\n",
    "ax = plt.subplot()\n",
    "ax.plot(image[820,:])\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_xlabel('Column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">What pixels define the overscan region? You can zoom in the plot if you need to get a better idea. Answer below: </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets plot the overscan region in the vertical direction to see if we can model it as a constant value or if it drifts as a function of the row number. Plot the average across the overscan region as a function of the row. Stay away from the edge near the live area of the CCD when calculating the averages just to be safe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the overscan region...\n",
    "# Hint: it turns out the first row has junk in it (the edges of images are often problematic)\n",
    "# so, ignore the first row (which in the image is actually the top row)\n",
    "\n",
    "# get size of image\n",
    "h, w = image.shape\n",
    "print(h,w)\n",
    "#initialize overscan array\n",
    "overscan = []\n",
    "\n",
    "# calculate mean overscan values\n",
    "for i in range(1,h):\n",
    "    overscan = np.append(overscan,image[i,....\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.plot(overscan)\n",
    "\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_xlabel('Row')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that there is systematic structure in the bias (it isn't just random noise). Most often people fit a polynomial to this structure and then subtract that model off the data. Here we will keep it simple and just ask you to subtract the mean value. Go ahead code that in and also trim the image to not have the overscan region or that pesky first row. \n",
    "\n",
    "By the way, you should also do the exact same thing to all of the images you have because they all have bias in them and the same overscan geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets load in the other images\n",
    "filename = 'imacs_bias.fits'\n",
    "hdu = fits.open(filename)[0]\n",
    "bias_image = hdu.data\n",
    "bias_hdr = hdu.header\n",
    "\n",
    "filename = 'superflat.fits'\n",
    "hdu = fits.open(filename)[0]\n",
    "flat_image = hdu.data\n",
    "flat_hdr = hdu.header\n",
    "\n",
    "# mean overscan value\n",
    "bias = overscan.mean()\n",
    "\n",
    "#subtract bias and trim image for all images\n",
    "...\n",
    "\n",
    "# plot the image, with minimum and maximum levels set by hand\n",
    "\n",
    "fig, axs = plt.subplots(1, 3,figsize=(20,8))\n",
    "\n",
    "ax1 = plt.subplot(131)\n",
    "...\n",
    "\n",
    "ax2 = plt.subplot(132)\n",
    "...\n",
    "\n",
    "ax3 = plt.subplot(133)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at all three images above. Did the trimming work like you expected? The object frame clearly still has residual structure that you can also see in the middle image, which is the superflat. We'll get to flat fielding next. Before moving on, lets take a look at the bias frame (the third one). There is clearly some structure left (partly because we didn't fit the vertical structure and just subtracted a mean value). We could go back and refit, or we could subtract this 2-d frame from the data and flat field frames. For now we're going to ignore this, but you should always be cognizant of remaining structure in your bias frames and subtract it if necessary (make sure that the structure is greater in value than the noise because any subtraction process is going to introduce the noise into your image). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatfielding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatfielding is the process by which you remove sensitivity variations across the detection. The basic principle is that if take an image of something that is uniform across the field of view, then any variations you see in that image are due to sensitivity variations in the detector. If you then divide your object frames by the image of the uniform source you will be 'dividing out' the sensitivity variations. \n",
    "\n",
    "What I am providing (the superflat) is one way to obtain such an image. Typically you take exposures of the inside of the dome (way out of focus) or a flat field screen mounted on the inside of the dome to mimic a uniform field. I didn't have such an exposure for this data so I did something that is also commonly done. I took the median of many exposures of the sky, hoping that the real objects (stars, galaxies) don't land on top of each other often and that the median just gives me an image of the smooth background sky (which is assumed to be uniform, but really isn't). Because I didn't have that many such frames with which to take the median, it didn't work perfectly (you can still see some residual images of bright stars). Nevertheless, we're going to go ahead and divide it out. \n",
    "\n",
    "First, before dividing it into the data, we will normalize the superflat (set it to have mean = 1) so that when we divide it into other frames we do not change their mean counts. Lets do all of that and take a look at the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean overscan value\n",
    "...\n",
    "\n",
    "#normalize flat\n",
    "...\n",
    "\n",
    "#divide image by flat\n",
    "...\n",
    "\n",
    "fig, axs = plt.subplots(1, 2,figsize=(16,8))\n",
    "\n",
    "...\n",
    "\n",
    "# write out your final reduced image (you'll need it for the next workbook\n",
    "fits.writeto('save.fits', final_image, hdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did that work? Did it improve things? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> Save your notebook.  Append your LastNameFirstInitial to the filename and submit via D2L. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
